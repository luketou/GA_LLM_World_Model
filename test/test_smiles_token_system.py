"""
æ¸¬è©¦ LLM SMILES Token æ¨™è¨˜ç³»çµ±
é©—è­‰ <SMILES></SMILES> æ¨™è¨˜çš„è§£æå’Œæå–åŠŸèƒ½
"""
import sys
import os
import logging

# Add project root to path
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_token_extraction():
    """æ¸¬è©¦ SMILES token æå–åŠŸèƒ½"""
    print("ğŸ§ª Testing SMILES Token Extraction System\n")
    
    from llm.generator import LLMGenerator
    
    # å‰µå»º mock LLM generatorï¼ˆä¸éœ€è¦çœŸå¯¦ API é‡‘é‘°ï¼‰
    class MockLLMGenerator(LLMGenerator):
        def __init__(self):
            self.max_smiles_length = 100
    
    generator = MockLLMGenerator()
    
    # æ¸¬è©¦æ¡ˆä¾‹
    test_cases = [
        {
            "name": "Perfect Token Format",
            "response": """<SMILES>c1ccc(Cl)cc1</SMILES>
<SMILES>c1ccc(Br)cc1</SMILES>
<SMILES>c1ccc(F)cc1</SMILES>""",
            "expected_count": 3
        },
        {
            "name": "Mixed Format with Noise",
            "response": """<think>
Let me generate some SMILES...
</think>

<SMILES>CCO</SMILES>
Some explanation text here...
<SMILES>CCN</SMILES>
Another line of text.
<SMILES>CCC</SMILES>""",
            "expected_count": 3
        },
        {
            "name": "Case Insensitive",
            "response": """<smiles>c1ccccc1</smiles>
<SMILES>Cc1ccccc1</SMILES>
<Smiles>Nc1ccccc1</Smiles>""",
            "expected_count": 3
        },
        {
            "name": "Inline Tokens",
            "response": """Here are the results: <SMILES>CCO</SMILES> and <SMILES>CCN</SMILES>
Also this one: <SMILES>CCC</SMILES>""",
            "expected_count": 3
        },
        {
            "name": "No Tokens (Fallback Test)",
            "response": """c1ccccc1
CCO
CCN
Some invalid text here
CCC""",
            "expected_count": 4  # Should fall back to line parsing
        },
        {
            "name": "Invalid SMILES Filtering",
            "response": """<SMILES>c1ccccc1</SMILES>
<SMILES>invalid_smiles_123</SMILES>
<SMILES>CCO</SMILES>
<SMILES>()()()invalid</SMILES>
<SMILES>CCN</SMILES>""",
            "expected_count": 3  # Only valid SMILES should be extracted
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"Test {i}: {test_case['name']}")
        print(f"Input response:")
        print(f"```\n{test_case['response']}\n```")
        
        try:
            extracted = generator._extract_smiles_from_response(test_case['response'])
            
            print(f"Extracted SMILES: {extracted}")
            print(f"Count: {len(extracted)} (expected: {test_case['expected_count']})")
            
            if len(extracted) == test_case['expected_count']:
                print("âœ… PASSED")
                passed += 1
            else:
                print("âŒ FAILED - Count mismatch")
                
        except Exception as e:
            print(f"âŒ FAILED - Exception: {e}")
        
        print("-" * 50)
    
    print(f"\nğŸ“Š Test Results: {passed}/{total} tests passed")
    return passed == total

def test_enhanced_prompts():
    """æ¸¬è©¦å¢å¼·çš„æç¤ºæ¨¡æ¿"""
    print("\nğŸ¯ Testing Enhanced Prompt Templates\n")
    
    from llm.prompt import create_enhanced_llm_messages, create_simple_generation_prompt, create_fallback_prompt
    
    # æ¸¬è©¦å‹•ä½œåˆ—è¡¨
    test_actions = [
        {"type": "substitute", "name": "add_chlorine", "description": "Add chlorine"},
        {"type": "scaffold_swap", "name": "swap_to_pyridine", "description": "Replace with pyridine"},
        {"type": "cyclization", "name": "form_ring", "description": "Form ring structure"}
    ]
    
    test_cases = [
        {
            "name": "Enhanced Messages",
            "function": create_enhanced_llm_messages,
            "args": ("c1ccccc1", test_actions)
        },
        {
            "name": "Simple Generation",
            "function": create_simple_generation_prompt,
            "args": ("c1ccccc1", 5)
        },
        {
            "name": "Fallback Prompt",
            "function": create_fallback_prompt,
            "args": ("c1ccccc1", 3)
        }
    ]
    
    passed = 0
    total = len(test_cases)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"Test {i}: {test_case['name']}")
        
        try:
            messages = test_case['function'](*test_case['args'])
            
            # æª¢æŸ¥æ¶ˆæ¯çµæ§‹
            assert isinstance(messages, list), "Messages should be a list"
            assert len(messages) >= 1, "Should have at least one message"
            assert all('role' in msg and 'content' in msg for msg in messages), "Each message should have role and content"
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å« SMILES token æ¨™è¨˜
            full_content = " ".join(msg['content'] for msg in messages)
            has_token_instruction = '<SMILES>' in full_content and '</SMILES>' in full_content
            
            print(f"Messages generated: {len(messages)}")
            print(f"Contains SMILES token instructions: {has_token_instruction}")
            
            if has_token_instruction:
                print("âœ… PASSED")
                passed += 1
            else:
                print("âŒ FAILED - Missing SMILES token instructions")
                print(f"Content preview: {full_content[:200]}...")
                
        except Exception as e:
            print(f"âŒ FAILED - Exception: {e}")
        
        print("-" * 50)
    
    print(f"\nğŸ“Š Prompt Test Results: {passed}/{total} tests passed")
    return passed == total

def test_integration():
    """æ¸¬è©¦æ•´åˆåŠŸèƒ½"""
    print("\nğŸ”§ Testing Integration with Mock LLM\n")
    
    # Mock LLM response that would come from a real API
    mock_llm_response = """<SMILES>c1ccc(Cl)cc1</SMILES>
<SMILES>c1ccc(Br)cc1</SMILES>
<SMILES>c1ccc(F)cc1</SMILES>
<SMILES>c1ccc(I)cc1</SMILES>
<SMILES>c1ccc(CN)cc1</SMILES>"""
    
    class MockLLMGenerator:
        def __init__(self):
            self.provider = "mock"
            self.model_name = "mock-model"
            self.temperature = 0.2
            self.max_tokens = 1000
            self.max_smiles_length = 100
            self.top_p = 1.0
            self.stream = False
            
        def validate_smiles(self, smiles: str) -> bool:
            """Simple validation without RDKit"""
            if not smiles or len(smiles) < 1:
                return False
            # Basic character check
            allowed_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789()[]=#+-@/\\%.')
            return all(c in allowed_chars for c in smiles)
            
        def _extract_smiles_from_response(self, response_text: str):
            """Use the real extraction method"""
            import re
            smiles_list = []
            
            # Extract SMILES from tokens
            pattern = r'<SMILES>(.*?)</SMILES>'
            matches = re.findall(pattern, response_text, re.IGNORECASE | re.MULTILINE)
            
            for match in matches:
                smiles = match.strip()
                if smiles and self.validate_smiles(smiles):
                    smiles_list.append(smiles)
            
            return smiles_list
    
    generator = MockLLMGenerator()
    
    try:
        extracted_smiles = generator._extract_smiles_from_response(mock_llm_response)
        
        print(f"Mock LLM Response:")
        print(f"```\n{mock_llm_response}\n```")
        print(f"Extracted SMILES: {extracted_smiles}")
        print(f"Count: {len(extracted_smiles)}")
        
        expected_count = 5
        if len(extracted_smiles) == expected_count:
            print("âœ… Integration test PASSED")
            return True
        else:
            print(f"âŒ Integration test FAILED - Expected {expected_count}, got {len(extracted_smiles)}")
            return False
            
    except Exception as e:
        print(f"âŒ Integration test FAILED - Exception: {e}")
        return False

def main():
    """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
    print("ğŸš€ Testing SMILES Token Marking System\n")
    
    tests = [
        test_token_extraction,
        test_enhanced_prompts,
        test_integration
    ]
    
    passed = 0
    total = len(tests)
    
    for test in tests:
        try:
            if test():
                passed += 1
        except Exception as e:
            print(f"Test failed with exception: {e}")
    
    print(f"\nğŸ‰ Overall Test Results: {passed}/{total} test suites passed")
    
    if passed == total:
        print("\nâœ… All tests passed! The SMILES token marking system is ready.")
        print("\nğŸ”§ Key Features Implemented:")
        print("  â€¢ <SMILES></SMILES> token-based extraction")
        print("  â€¢ Robust regex and fallback parsing")
        print("  â€¢ Enhanced prompt templates with examples")
        print("  â€¢ Multi-level prompt strategies")
        print("  â€¢ Improved SMILES validation")
    else:
        print("\nâŒ Some tests failed. Please check the implementation.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)